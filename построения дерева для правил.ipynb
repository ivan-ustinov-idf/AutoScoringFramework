{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import scipy.stats.stats as stats\n",
    "import re\n",
    "import math\n",
    "from datetime import datetime\n",
    "import importlib\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LassoCV, RidgeClassifierCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedKFold, GridSearchCV \n",
    "from sklearn.metrics import roc_auc_score, roc_curve, log_loss, f1_score, confusion_matrix, precision_score, recall_score, classification_report;\n",
    "import time\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlxtend\n",
    "# !pip install lightgbm\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoscoring.AS import *\n",
    "from autoscoring.AS_2 import *\n",
    "from autoscoring.Binning import transform_df_to_woe, construction_binning, create_num_intervals, create_dict_cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/ExcelSelfEmployed_rules.xlsx', sheet_name = 'Sheet1')\n",
    "\n",
    "df['date_requested'] = pd.to_datetime(df['date_requested'])\n",
    "DATE = 'date_requested'  # Дата, по которой аггрегировать и оценивать gini/psi и т.д. по дефолту дата выдачи.\n",
    "df[DATE] = pd.to_datetime(df[DATE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nЗапускать эту ячейку, только если есть данная проблема c приведением типво данных.\\nИначе можно пропустить.\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В некоторых случаях при загрузке из excel файла может произойти проблема,\n",
    "# связанная с тем, что в excel вещественные числа разделяются запятой,\n",
    "# а в python разделение идёт по точке.\n",
    "# Если возникла такая проблема, то можно заменить все запятые на точки и сделать преобразование типовю\n",
    "\n",
    "# Запускать эту ячейку, только если есть данная проблема. Иначе можно пропустить.\n",
    "'''\n",
    "Запускать эту ячейку, только если есть данная проблема c приведением типво данных.\n",
    "Иначе можно пропустить.\n",
    "\n",
    "'''\n",
    "for col in df.select_dtypes(include=object).columns:\n",
    "    if col == DATE:\n",
    "        continue\n",
    "    df[col] = df[col].apply(lambda x: str(x).replace(',', '.'))\n",
    "\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "df[DATE] = pd.to_datetime(df[DATE], format='%Y-%m-%d')\n",
    "df = df.replace('nan', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задание названия переменной, являющейся таргетом\n",
    "TARGET = 'npl1_1_7dpd'\n",
    "df = df[df[TARGET].isna() == False]\n",
    "\n",
    "# Фильтрация требуемого сегмента\n",
    "df = df[(df['product_group'] == 'MICRO_SELF_EMPLOYED')]\n",
    "\n",
    "df['target'] = df[TARGET]\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values (np.nan, '_MISSING_')\n",
    "cat_vars = df.select_dtypes(include=[object]).columns\n",
    "df = filling(df)\n",
    "\n",
    "min_num = 50\n",
    "# Можно задать список признаков, который не будет учавствовать в предобработке\n",
    "ignore_vars = ['date_requested', 'credit_id', 'target', DATE]\n",
    "df, else_df = replace_not_frequent_2(df, cat_vars, num_min=min_num, ignore_vars=ignore_vars)\n",
    "\n",
    "# Drop columns with only 1 value\n",
    "df = drop_single_value_column(df, except_cols=ignore_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем лишние колонки, конкретный набор зависит от сэмпла.\n",
    "cols_to_drop = [var for var in df.columns if 'SCOR' in var or 'street' in var or 'scoring' in var]\n",
    "df.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение WOE таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 40, number of negative: 1352\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14809\n",
      "[LightGBM] [Info] Number of data points in the train set: 1392, number of used features: 278\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028736 -> initscore=-3.520461\n",
      "[LightGBM] [Info] Start training from score -3.520461\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Задаём набор признаков для формирования биннинга.\n",
    "# Набор колонок, который не будет учавствовать в построении карты\n",
    "technical_features = ['client_type2', 'credit_id',\n",
    "                      'date_requested', 'target', 'npl1_1_7dpd', DATE]\n",
    "technical_features = list(set(technical_features))\n",
    "# Задаём набор признаков, которые будут учавствовать в биннинге,\n",
    "# для этого удаляем все ненужные признаки из общего списка переменных.\n",
    "features = df.drop(\n",
    "    technical_features\n",
    ", axis=1).columns\n",
    "\n",
    "target_name = 'target'  # Наименование столбца - таргета\n",
    "# Минимальное количество объектов в бине, по дефолту 0.05, требуется менять\n",
    "# только в исключительных ситуациях\n",
    "min_bin_size = 0.05\n",
    "max_bin_count = 5  # Максимальное количество бинов при разбиении, по дефолту 5 - хороший вариант.\n",
    "# Как определять WOE для пропусков, если их меньше чем min_bin_size:\n",
    "# max - максимальное WOE\n",
    "# max_cat - WOE самой крупной группы, можно оставить это по дефолту\n",
    "# min - минимальное WOE\n",
    "# zero - значение WOE становится 0\n",
    "nan_to_woe = 'max_cat'\n",
    "# Как определять WOE для _ELSE_ значений, если их меньше чем min_bin_size:\n",
    "# max - максимальное WOE\n",
    "# max_cat - WOE самой крупной группы, можно оставить это по дефолту\n",
    "# min - минимальное WOE\n",
    "# zero - значение WOE становится 0\n",
    "else_to_woe = 'max_cat'\n",
    "# Если True, то специально накладываются ограничения, чтобы WOE был монотонным по бинам,\n",
    "# лучше оставить False, и потом в ручном режиме поменять, если не требуется обратного.\n",
    "monotonic = False\n",
    "n_jobs = 4  # Количество ядер для работы, чем больше тем быстрее, по дефолту 4.\n",
    "\n",
    "iv_df, dropped_feats, feats, best_features, auto_woe = construction_binning(df, features, target_name,\n",
    "                                                         max_bin_count=max_bin_count,\n",
    "                                                         min_bin_size=min_bin_size,\n",
    "                                                         nan_to_woe=nan_to_woe,\n",
    "                                                         else_to_woe=else_to_woe,\n",
    "                                                         monotonic=monotonic,\n",
    "                                                         n_jobs=n_jobs)\n",
    "\n",
    "# iv_df - таблицы WOE биннинга\n",
    "# dropped_feats - набор переменных, для которых биннинг не посчитался,\n",
    "# т.к. в переменной не нашлось сколько-нибудь хорошего разделения или признак практически константный\n",
    "# feats - таблица полученная после предварительного отбора признаков, в которой указаны причины,\n",
    "# по которым признак не очень хороший, можно игнорировать\n",
    "# best_features - набор признаков после предварительного отбора внутри AutoML,\n",
    "# можно использовать при дальнейшем отборе, можно проигнорировать\n",
    "# auto_woe - техническая переменная, можно игнорировать"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вначале сделаем отбор переменных, далее будет подготовка признаков и построения дерева решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Набор обязательных признаков (для примера), которые должны остаться несмотря на отбор.\n",
    "# Разкомментировать, если он нужен.\n",
    "\n",
    "# mandatory_feats = ['credits_active_owner', 'credits_all_owner']\n",
    "# mandatory_feats_woe = ['WOE_' + col for col in mandatory_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "# Порог для фильтрации по IV.\n",
    "# Требуется устанавливать в зависимости от количества признаков, но лучше сильно не ограничивать.\n",
    "# Например если признаков меньше 200, то можно поставить iv_co = 0.01 или 0.02.\n",
    "# Иначе можно поставить iv_co = 0.03 - 0.05.\n",
    "iv_co = 0.05\n",
    "features_iv = iv_df[iv_df['IV'] > iv_co]['VAR_NAME'].unique()\n",
    "print(len(features_iv))\n",
    "\n",
    "# Добавялем к списку обязательные переменные, если требуется\n",
    "# vars = add_mandatory_feats(vars, mandatory_feats)\n",
    "\n",
    "IV = iv_df[['VAR_NAME', 'IV']].drop_duplicates()\n",
    "IV = IV[IV['VAR_NAME'].isin(features_iv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features left after IV drop: 139\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# Данные подготовка нужна, чтобы быстрее сделать преобразование\n",
    "iv_df = create_num_intervals(iv_df)\n",
    "dict_cat_feats = create_dict_cat_feats(iv_df)\n",
    "\n",
    "iv_co = None\n",
    "X, y = transform_df_to_woe(df[features_iv], y, IV, iv_df, dict_cat_feats, iv_cut_off=iv_co, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: [] \n",
      "\n",
      "Features left after correlation check: 139 \n",
      "\n",
      "Not dropped columns: ['reapeted_app', 'days_from_fc_d_requested', 'days_from_last_c_d_requested', 'days_from_last_c_d_repaid', 'avg_expired_days', 'max_expired_days', 'penalty_cnt', 'count_repaid', 'early_repaid', 'credits_all_owner', 'mnt_outstand_balance', 'his_w_pay_st_by_act_crd_days', 'his_w_pay_st_by_act_crd_sum', 'his_w_pay_st_by_cls_crd_days', 'his_w_pay_st_by_cls_crd_sum', 'act_div_all_crd', 'sum_per_cred', 'h_cl_sum_div_days', 'h_ac_sum_div_days', 'cur_ac_sum_div_h_ac_sum', 'mnt_inst_owner_div_frst_cr', 'mnt_outstand_balance_div_frst_cr', 'fc_credits_active_owner', 'fc_credits_all_owner', 'fc_monthly_instalments_owner', 'fc_mnt_outstand_balance', 'fc_his_w_pay_st_by_act_crd_days', 'fc_his_w_pay_st_by_act_crd_sum', 'fc_his_w_pay_st_by_cls_crd_days', 'fc_his_w_pay_st_by_cls_crd_sum', 'fc_act_div_all_crd', 'fc_sum_per_cred', 'fc_h_cl_sum_div_days', 'fc_h_ac_sum_div_days', 'fc_cur_ac_sum_div_h_ac_sum', 'fc_h_ac_sum_div_h_cl_sum', 'fcb_last_open_d_cr_act', 'fcb_last_open_d_cr_all', 'fcb_first_cred_open', 'fcb_first_cred_open_act', 'fcb_first_Othr_credit', 'fcb_first_POS_credit', 'average_amount_opv', 'average_monthly_income', 'conf_income_per', 'cnt_pdl_act', 'cnt_pdl_all', 'cnt_IL_comp', 'cnt_IL_act', 'cnt_IL_all', 'cnt_IL_exp', 'cnt_all_exp', 'min_IL_last_pay', 'min_all_last_pay', 'sum_IL_credit_sum', 'sum_all_credit_sum', 'IL_no_deep_delinq', 'min_IL_planned_close_date', 'min_all_planned_close_date', 'cnt_all_past_due', 'cnt_pdl_act_no_Crd', 'cnt_pdl_all_no_Crd', 'cnt_IL_comp_no_Crd', 'cnt_IL_act_no_Crd', 'cnt_IL_all_no_Crd', 'sum_IL_credit_sum_no_Crd', 'sum_all_credit_sum_no_Crd', 'min_IL_planned_close_date_no_Crd', 'min_PDL_planned_close_date_no_Crd', 'min_all_planned_close_date_no_Crd', 'open_date_cnt_7d', 'open_date_cnt_30d', 'open_date_cnt_90d', 'open_date_cnt_360d', 'dependants_count', 'bor_age', 'work_amount', 'education', 'mail_score', 'fc_mail_score', 'creation_date', 'requested_amount', 'requested_amount_to_pay', 'req_an_amount', 'requested_credit_count_days', 'MIO_req_an', 'average_monthly_income123', 'average_monthly_income_i', 'last_deduction_date', 'DTI_2', 'requested_annuity_amount', 'capsL7d', 'capsL1m', 'capsL3m', 'capsL6m', 'capsL12mas', 'capsMaxAmnt', 'ascapsMinAmnt', 'capsMinAmntLocation', 'capsTotalAmountL1d', 'capsTotalAmountL7d', 'capsTotalAmountL1m', 'capsTotalAmountL3m', 'capsTotalAmountL6m', 'capsTotalAmountL12m', 'PTI_11', 'pti7', 'DTI_11', 'cnt_error_enpf', 'main_score', 'all_min_reg', 'all_max_reg', 'all_smoking', 'count_profiles', 'sum_gifts_n', 'sum_groups_n', 'sum_likes_n', 'sum_wall_postN', 'avg_fr_age', 'avg_score', 'avg_photos_n', 'fcb_date_diff', 'board_ad_count', 'credit_number', 'KMF_completed', 'alfa_completed', 'centre_completed', 'halyk_completed', 'home_completed', 'NumberOfOverdueInstalmentsMax', 'PDL_IL', 'maritalStatus', 'industry', 'operators', 'credit_purpose', 'pti5', 'partner_group', 'all_marry', 'client_type'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем порого для фильтрации признаков по корреляциям.\n",
    "# По дефолту 0.85 - оптимальное значение, в зависимости от требований\n",
    "# можно поставить число в диапозоне 0.75 - 0.9.\n",
    "cut_off = 0.85\n",
    "X_train_corr = delete_correlated_features(X, cut_off=cut_off, is_plot_prev=False,\n",
    "                                          exclude=[], IV_sort=True, iv_df=iv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[X_train_corr.columns]\n",
    "X.columns = 'WOE_' + X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фильтруем признаки по следующему принципу:\n",
    "# для каждого признака делаем однофакторный расчёт gini на train выборке для каждого месяца\n",
    "# в разбивке по DATE (обязательно должен присутствовать в df_train).\n",
    "# После этого отфильтровываем признаки, для которых gini меньше чем gini_min\n",
    "# для количества интервалов большего num_bad_intervals.\n",
    "# Т.е. например, если gini_min=0.05 и num_bad_intervals=2, то если gini переменной больше 0.05 для всех месяцев, кроме одного - это ок. \n",
    "gini_min = 0.05  # 0.05 - по дефолту норм, можно взять в диапозоне 0.02 - 0.08 в зависимости от качества признаков.\n",
    "num_bad_intervals = 2  # 2 месяца/недели по дефолту норм, можно взять 10-20% от общего количества месяцев в сэмпле.\n",
    "date_name = DATE  # Дата, по которой делить на месяцы.\n",
    "intervals = 'month'  # Интервалы времени для разбивки, month или week\n",
    "\n",
    "gini_feats, df_gini_months = gini_month_selection(X, df, gini_min=gini_min,\n",
    "                                                  num_bad_intervals=num_bad_intervals, date_name=date_name,\n",
    "                                                  intervals=intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки по их значимости во время построения Деревьев решений.\n",
    "top_n = 50  # Количество лучшеих признаков, которые оставить. Можно брать в диапозоне 45-80.\n",
    "rf_feats, rf_imp = rf_feature_selection(X[gini_feats], y, top_n=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем признаки исходя из permutations_importance.\n",
    "# Подробнее: https://www.kaggle.com/dansbecker/permutation-importance\n",
    "top_n = 35  # Количество лучшеих признаков, которые оставить. Можно брать в диапозоне 30-50.\n",
    "tf_feats, tf_imp = permutation_two_forest_selection(X[rf_feats], y, top_n=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Итоговый набор переменных, который будет учавтсовать в построении дерева.\n",
    "vars = [var.replace('WOE_', '') for var in tf_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заново добавляем список обязательных признаков.\n",
    "# vars = add_mandatory_feats(vars, mandatory_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fcb_first_cred_open_act',\n",
       " 'fc_his_w_pay_st_by_cls_crd_sum',\n",
       " 'bor_age',\n",
       " 'mnt_outstand_balance',\n",
       " 'average_monthly_income',\n",
       " 'requested_amount_to_pay',\n",
       " 'capsL1m',\n",
       " 'average_monthly_income123',\n",
       " 'sum_all_credit_sum',\n",
       " 'cnt_IL_all',\n",
       " 'work_amount',\n",
       " 'fc_monthly_instalments_owner',\n",
       " 'capsL3m',\n",
       " 'fc_h_cl_sum_div_days',\n",
       " 'DTI_11',\n",
       " 'fcb_first_cred_open',\n",
       " 'PTI_11',\n",
       " 'fcb_last_open_d_cr_all',\n",
       " 'cnt_IL_comp_no_Crd',\n",
       " 'fc_act_div_all_crd',\n",
       " 'last_deduction_date',\n",
       " 'maritalStatus',\n",
       " 'average_amount_opv',\n",
       " 'fc_his_w_pay_st_by_act_crd_sum',\n",
       " 'his_w_pay_st_by_cls_crd_sum',\n",
       " 'pti7',\n",
       " 'his_w_pay_st_by_act_crd_sum',\n",
       " 'all_min_reg',\n",
       " 'fc_credits_all_owner',\n",
       " 'fc_h_ac_sum_div_days',\n",
       " 'fc_mnt_outstand_balance',\n",
       " 'requested_credit_count_days',\n",
       " 'sum_groups_n',\n",
       " 'min_all_planned_close_date_no_Crd',\n",
       " 'fcb_date_diff']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем подготовку данных перед построением дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df.copy()\n",
    "# df = df_base.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = df[vars].select_dtypes(include=object).columns\n",
    "num_feat = df[vars].select_dtypes(exclude=object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Составляем таблицы соответсвия при кодировани, чтобы можно было декодировать значения.\n",
    "dict_cat_encoding = {}\n",
    "for feat in cat_feat:\n",
    "    target_encoder = ce.target_encoder.TargetEncoder(smoothing=0.1)\n",
    "    target_encoder.fit(df[[feat]], df[TARGET])\n",
    "\n",
    "    values = df[[feat]].drop_duplicates().copy()\n",
    "    encoding = target_encoder.transform(values)\n",
    "    encoding.columns = [f'{feat}_enc']\n",
    "\n",
    "    dict_cat_encoding[feat] = pd.concat([values, encoding], axis=1).reset_index(drop=True)\n",
    "\n",
    "# Кодируем категориальный переменные.\n",
    "target_encoder = ce.target_encoder.TargetEncoder(smoothing=0.1)\n",
    "df[cat_feat] = target_encoder.fit_transform(df[cat_feat], df[TARGET])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Заполняем NaN\n",
    "\n",
    "Есть 3 варианта заполнения:\n",
    "* Явно задать значения для NaN различных признаков\n",
    "* Медианным значением\n",
    "* Заполнить автоматически наиболее подходящим с точки зрения дефолтности значением\n",
    "Явно задем значение для NaN\n",
    "\n",
    "<b>Требутся выбрать одно из 3ех, лучше всего последнее при прочих равных.</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явно задаем значение для NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Требуется явно задать значения для NaN\n",
    "dict_nan_encoding = {\n",
    "    # '<Наименование признака>': <значение, на которое делать замену NaN>,\n",
    "}\n",
    "for feat, val in dict_nan_encoding.items():\n",
    "    df[feat].fillna(val, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем медианой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nan_encoding = {}\n",
    "# Заполняем NaN значения медианой данного количественного признака\n",
    "for feat in num_feat:\n",
    "    if dict_nan_encoding.get(feat) is None:\n",
    "        dict_nan_encoding[feat] = df[feat].median()\n",
    "    df[feat].fillna(df[feat].median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Автоматический подбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Автоматически ищем наиболее подходящую замену NaN с точки зрения дефолтности сегментов.\n",
    "dict_nan_encoding = {}\n",
    "\n",
    "for feat in num_feat:\n",
    "    if df[feat].isna().sum() == 0:\n",
    "        continue\n",
    "\n",
    "    d3 = iv_df[iv_df['VAR_NAME'] == feat]\n",
    "    dr_nan = d3.loc[d3['MIN_VALUE'].isna() == True, 'DR'].values[0]\n",
    "\n",
    "    ind_for_nan = np.argmin(np.abs(d3[d3['MIN_VALUE'].isna() != True]['DR'] - dr_nan))\n",
    "    segment_for_nan = d3[d3['MIN_VALUE'].isna() != True].iloc[ind_for_nan]\n",
    "\n",
    "    value = df[(df[feat] > segment_for_nan['MIN_VALUE']) & (df[feat] < segment_for_nan['MAX_VALUE'] + 0.001)][feat].median()\n",
    "\n",
    "    if dict_nan_encoding.get(feat) is None:\n",
    "        dict_nan_encoding[feat] = value\n",
    "    df[feat].fillna(value, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем метод заполнения NaN и кодировку категориальных переменных в excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'result_rules/encoding_methods'  # Наименование файла, куда сохранять информацию\n",
    "save_encoding_excel(dict_cat_encoding, dict_nan_encoding, name=name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим дерево решений\n",
    "\n",
    "В каждом прямоугольнике расположена следующая информация:\n",
    "* решающее правило для разделения на следующем уровне, например: fcb_first_cred_open <= 83.0\n",
    "* количество объектов в данном узле: samples = 1740\n",
    "* размеры классов: value = [1688 (количество класса 0), 52 (количество класса 1)]\n",
    "\n",
    "Далее на следующей уровне будет разделение по текущему правилу. Объекты, удовлетворяющие ему пойдут влево, другие пойдут вправо.\n",
    "\n",
    "Так после правила \"fcb_first_cred_open <= 83.0\" влевом узле будут объекты, для которых это верно (value=[48, 12]), остальные пойдут в правый узел (value=[1640, 40])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для построения и визуализации нескольких деревьев решений.\n",
    "# Параметры:\n",
    "#     Обязательные:\n",
    "#         - df (DataFrame): Исходный DataFrame, содержащий данные для обучения модели.\n",
    "#         - vars (list): Список признаков, используемых для обучения модели.\n",
    "#         - TARGET (str): Имя целевой переменной.\n",
    "#     Опциональные:\n",
    "#         - num_forests (int): Количество деревьев с разными случайными наборами признаков. По умолчанию 1.\n",
    "#         - min_samples_leaf (int): Минимальное количество объектов в одном листе дерева. По умолчанию 60.\n",
    "#         - max_depth (int): Максимальная глубина дерева. По умолчанию 3.\n",
    "#         - percent_feat (float): Процент признаков, который брать для построения нового дерева. По умолчанию 1.0.\n",
    "#         - pic_name (str): Путь и имя для сохранения изображения. По умолчанию 'result_rules/example_tree_structure_0_v'.\n",
    "#         - show_image (bool): Параметр для отображения или не отображения картинки. По умолчанию True.\n",
    "#         - full_info (bool): Параметр для вывода полной информации в узлах или только условие, Gini, Samples, Value. По умолчанию True.\n",
    "\n",
    "visualize_decision_trees(df, vars, TARGET, num_forests=4,\n",
    "                        min_samples_leaf=60, max_depth=3, percent_feat=0.7,\n",
    "                        pic_name='result_rules/example_tree_structure2_v.png', \n",
    "                        show_image=True, full_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_forests = 4  # Количество деревьев с разным случайным набором признаков.\n",
    "min_samples_leaf = 60  # Минимальное количество объектов в одном листе дерева.\n",
    "max_depth = 3  # Максимальная глубина дерева.\n",
    "percent_feat = 0.7  # Процент признаков, который брать для построения нового дерева.\n",
    "pic_name = 'result_rules/example_tree_structure2_v.png'  # Где и под каким именем сохранять картинки\n",
    "\n",
    "\n",
    "for i in range(1, num_forests+1):\n",
    "    __vars = [np.random.choice(vars) for i in range(int(len(vars) * percent_feat))]\n",
    "    clf_tree = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=142)\n",
    "    clf_tree.fit(df[__vars], df[TARGET])\n",
    "\n",
    "    fig = plt.figure(figsize=(100,80))\n",
    "    _ = tree.plot_tree(clf_tree, \n",
    "                    feature_names=__vars,\n",
    "                    #  class_names=['good', 'bad'],\n",
    "                    #    filled=True\n",
    "                    )\n",
    "    fig.savefig(pic_name[:-4] + str(i) + pic_name[-4:])\n",
    "    # plt.show()  # чтобы отрисовывать деревья\n",
    "    plt.close()  # чтобы не отрисовывать деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d4a84df06a21ef7e8194d58f2af03df39245d94ccaa61e1bce2ddd04a1c859b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 ('work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
